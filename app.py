# app.py

import streamlit as st
import os
from dotenv import load_dotenv
load_dotenv()  # ‚¨ÖÔ∏è ‡∏ï‡πâ‡∏≠‡∏á‡πÇ‡∏´‡∏•‡∏î .env ‡∏Å‡πà‡∏≠‡∏ô

print("üîê OpenAI API Key:", os.getenv("OPENAI_API_KEY"))  # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ñ‡πà‡∏≤

from agents.agent_ba import get_ba_answer
from agents.agent_pm import get_pm_answer
from agents.agent_qa import get_qa_answer
from agents.agent_all import get_all_answer
from langchain_community.document_loaders import PyPDFLoader, CSVLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings
from io import BytesIO
from pypdf.errors import EmptyFileError

from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import OpenAIEmbeddings

embedding = OpenAIEmbeddings()

# Utility function
def build_all_vector():
    embedding = OpenAIEmbeddings()

    vector_paths = {
        "ba": "vector_db/ba",
        "pm": "vector_db/pm",
        "qa": "vector_db/qa"
    }

    vector_dbs = []

    for role, path in vector_paths.items():
        index_path = os.path.join(path, "index.faiss")
        if os.path.exists(index_path):
            db = FAISS.load_local(path, embedding, allow_dangerous_deserialization=True)
            vector_dbs.append(db)
        else:
            print(f"‚ö†Ô∏è ‡∏Ç‡πâ‡∏≤‡∏° {role.upper()} ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå: {index_path}")

    if not vector_dbs:
        print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÉ‡∏î‡πÜ ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏£‡∏ß‡∏°")
        return

    # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å db ‡πÅ‡∏£‡∏Å
    db_all = vector_dbs[0]
    for db in vector_dbs[1:]:
        db_all.merge_from(db)

    db_all.save_local("vector_db/all")
    print("‚úÖ ‡∏£‡∏ß‡∏°‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")


def process_files(uploaded_files, agent="ba"):
    folder_path = f"docs/{agent}"
    os.makedirs(folder_path, exist_ok=True)
    all_docs = []

    for file in uploaded_files:
        if hasattr(file, "name") and hasattr(file, "getbuffer"):
            filepath = os.path.join(folder_path, os.path.basename(file.name))
            with open(filepath, "wb") as f:
                f.write(file.getbuffer())
        else:
            filepath = file.name

        if os.path.getsize(filepath) == 0:
            st.warning(f"‚ö†Ô∏è ‡∏Ç‡πâ‡∏≤‡∏°‡πÑ‡∏ü‡∏•‡πå‡∏ß‡πà‡∏≤‡∏á: {filepath}")
            continue

        try:
            if filepath.endswith(".csv"):
                loader = CSVLoader(file_path=filepath)
            else:
                loader = PyPDFLoader(file_path=filepath)
            data = loader.load()
            all_docs.extend(data)
        except EmptyFileError:
            st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ß‡πà‡∏≤‡∏á‡πÑ‡∏î‡πâ: {filepath}")
        except Exception as e:
            st.error(f"‚ùå ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {filepath}\n{str(e)}")

    if not all_docs:
        st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏î‡πâ")
        return

    chunks = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100).split_documents(all_docs)
    db = FAISS.from_documents(chunks, embedding)
    db.save_local(f"vector_db/{agent}")

# UI
st.set_page_config(page_title="AI Project Assistant", layout="wide")
st.title("ü§ñ AI Project Assistant")

# Sidebar - Upload
st.sidebar.markdown("## üìÅ Upload Documents")

def make_fake_file(path):
    with open(path, "rb") as f:
        content = f.read()
    class FakeFile:
        def __init__(self, name, content):
            self.name = name
            self._content = content
        def getbuffer(self):
            return BytesIO(self._content).getbuffer()
    return FakeFile(os.path.basename(path), content)

with st.sidebar.expander("üìÑ Upload for BA Agent"):
    uploaded_ba = st.file_uploader("Upload PDF/DOCX for BA", type=["pdf", "docx"], accept_multiple_files=True)
    if uploaded_ba:
        process_files(uploaded_ba, agent="ba")
        st.success("‚úÖ BA documents processed!")

    if st.button("üîÅ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå BA ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà"):
        ba_folder = "docs/ba"
        existing_files = [make_fake_file(os.path.join(ba_folder, f)) for f in os.listdir(ba_folder) if f.endswith((".pdf", ".docx", ".csv"))]
        process_files(existing_files, agent="ba")
        st.success("‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏Å‡πà‡∏≤‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå BA ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß")

with st.sidebar.expander("üìÑ Upload for PM Agent"):
    uploaded_pm = st.file_uploader("Upload PDF/CSV for PM", type=["pdf", "csv"], accept_multiple_files=True, key="pm")
    if uploaded_pm:
        process_files(uploaded_pm, agent="pm")
        st.success("‚úÖ PM documents processed!")

    if st.button("üîÅ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå PM ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà"):
        pm_folder = "docs/pm"
        existing_files = [make_fake_file(os.path.join(pm_folder, f)) for f in os.listdir(pm_folder) if f.endswith((".pdf", ".docx", ".csv"))]
        process_files(existing_files, agent="pm")
        st.success("‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏Å‡πà‡∏≤‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå PM ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß")

with st.sidebar.expander("üìÑ Upload for QA Agent"):
    uploaded_qa = st.file_uploader("Upload PDF/CSV for QA", type=["pdf", "csv"], accept_multiple_files=True, key="qa")
    if uploaded_qa:
        process_files(uploaded_qa, agent="qa")
        st.success("‚úÖ QA documents processed!")

    if st.button("üîÅ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå QA ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà"):
        qa_folder = "docs/qa"
        existing_files = [make_fake_file(os.path.join(qa_folder, f)) for f in os.listdir(qa_folder) if f.endswith((".pdf", ".docx", ".csv"))]
        process_files(existing_files, agent="qa")
        st.success("‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏Å‡πà‡∏≤‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå QA ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß")

with st.sidebar.expander("üìÑ ‡∏£‡∏ß‡∏°‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå All-in-One Agent"):
    if st.button("üîÅ ‡∏£‡∏ß‡∏°‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"):
        try:
            build_all_vector()
            st.success("‚úÖ ‡∏£‡∏ß‡∏°‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß")
        except Exception as e:
            st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏ß‡∏°‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå: {str(e)}")


# Chat Interface
agent_choice = st.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Agent ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ñ‡∏≤‡∏°:", ["BA", "PM", "QA", "All-in-One"])
query = st.text_input("‚ùì ‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå:")

if st.button("‡∏ñ‡∏≤‡∏°‡πÄ‡∏•‡∏¢") and query:
    with st.spinner("AI ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏¥‡∏î..."):
        try:
            if agent_choice == "BA":
                answer = get_ba_answer(query)
            elif agent_choice == "PM":
                answer = get_pm_answer(query)
            elif agent_choice == "QA":
                answer = get_qa_answer(query)
            else:
                answer = get_all_answer(query)

            st.markdown(f"### üí¨ ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:\n{answer}")
        except Exception as e:
            st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}")
